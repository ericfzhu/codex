{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Path to the EPUB file and the output CSV file\n",
    "epub_file_path = 'calendar of wisdom.epub'\n",
    "output_csv_file = 'quotes.csv'\n",
    "# Read EPUB content\n",
    "book = epub.read_epub(epub_file_path)\n",
    "content = []\n",
    "for item in book.get_items():\n",
    "    if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "        content.append(item.get_body_content())\n",
    "\n",
    "# Parse quotes and authors\n",
    "quotes_data = []\n",
    "for html_content in content:\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    for quote_tag in soup.find_all('p', class_='calibre15'):\n",
    "        quote = quote_tag.get_text(strip=True)\n",
    "\n",
    "        # Find the author in the next sibling with class 'calibre16'\n",
    "        author_tag = quote_tag.find_next_sibling('p', class_='calibre16')\n",
    "        author = author_tag.get_text(strip=True) if author_tag else \"Unknown Author\"\n",
    "\n",
    "        quotes_data.append((quote, author))\n",
    "\n",
    "# Save to CSV\n",
    "with open(output_csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Quote', 'Author'])  # Writing header\n",
    "    for quote, author in quotes_data:\n",
    "        writer.writerow([quote, author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_epub(file_path):\n",
    "    book = epub.read_epub(file_path)\n",
    "    content = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            content.append(item.get_body_content())\n",
    "    return content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epub_file_path = 'calendar of wisdom.epub'\n",
    "\n",
    "    content = read_epub(epub_file_path)\n",
    "    # Print the first 1000 characters of the first document's content to inspect the structure\n",
    "    with open('content_sample.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(content[5][:5000].decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/bl_0d1jx5p7188qwkby02g5w0000gn/T/ipykernel_85083/1746783764.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "goodreads_quotes = pd.read_csv('goodreads_quotes.csv')\n",
    "quotes = pd.read_csv('quotes.csv')\n",
    "quotes_and_authors = pd.read_csv('quotes_and_authors.csv')\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_quotes = pd.concat([goodreads_quotes, quotes, quotes_and_authors])\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_quotes.to_csv('combined_quotes.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows where 'Quote' is empty or null\n",
    "combined_quotes = combined_quotes[combined_quotes['Quote'].notna()]\n",
    "\n",
    "# Save the cleaned dataframe to a new CSV file\n",
    "combined_quotes.to_csv('cleaned_combined_quotes.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascraper-14KvqXQX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
